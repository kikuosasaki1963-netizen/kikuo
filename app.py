"""Voice Generator Web App - Streamlit (No pydub)"""
import os
import re
import wave
import tempfile
import struct
import streamlit as st
from google import genai
from google.genai import types
from docx import Document
import io
import subprocess

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Voice Generator",
    page_icon="ğŸ™ï¸",
    layout="centered"
)

st.title("ğŸ™ï¸ Voice Generator")
st.write("å¯¾è©±ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰æ„Ÿæƒ…è±Šã‹ãªéŸ³å£°ã‚’ç”Ÿæˆã—ã¾ã™")

# APIã‚­ãƒ¼è¨­å®šï¼ˆSecretsã‹ã‚‰å–å¾—ï¼‰
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")

if not GEMINI_API_KEY:
    st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Streamlit Cloudã®Secretsã«GEMINI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
@st.cache_resource
def get_client():
    return genai.Client(api_key=GEMINI_API_KEY)

client = get_client()

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆè§£æ
def parse_dialogue(content):
    segments = []

    # æ§˜ã€…ãªå½¢å¼ã‚’çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
    # Speaker 1/2 â†’ è©±è€…1/2
    content = content.replace('Speaker 1:', '[è©±è€…1]:')
    content = content.replace('Speaker 2:', '[è©±è€…2]:')

    # ï¼ˆè©±è€…1ï¼‰ã‚„ï¼ˆè©±è€…ï¼’ï¼‰â†’ [è©±è€…1]
    content = re.sub(r'ï¼ˆ(è©±è€…\d+)ï¼‰[:ï¼š]?\s*', r'[\1]: ', content)
    content = re.sub(r'\((è©±è€…\d+)\)[:ï¼š]?\s*', r'[\1]: ', content)

    # å…¨è§’æ•°å­—ã‚’åŠè§’ã«å¤‰æ›
    content = content.replace('ï¼‘', '1').replace('ï¼’', '2').replace('ï¼“', '3')
    content = content.replace('ï¼”', '4').replace('ï¼•', '5')

    # è©±è€…1: ã‚„ è©±è€…2: ï¼ˆæ‹¬å¼§ãªã—ï¼‰â†’ [è©±è€…1]:
    content = re.sub(r'(?<!\[)(è©±è€…\d+)[:ï¼š]\s*', r'[\1]: ', content)

    # A: B: ãªã©ã®ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆè©±è€…
    content = re.sub(r'^([A-Za-z])[:ï¼š]\s*', r'[\1]: ', content, flags=re.MULTILINE)

    # è¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œ
    pattern = r'\[(è©±è€…\d+|[^\]]+)\][:ï¼š]?\s*(.+)'
    for match in re.finditer(pattern, content):
        speaker = match.group(1).strip()
        text = match.group(2).strip()
        if text:
            segments.append({"speaker": speaker, "text": text})
    return segments

# Wordãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
def read_word_file(uploaded_file):
    doc = Document(io.BytesIO(uploaded_file.read()))
    text = '\n'.join([p.text for p in doc.paragraphs])

    # Speaker 1/2 ã‚’ è©±è€…1/2 ã«å¤‰æ›
    text = text.replace('Speaker 1:', '[è©±è€…1]:')
    text = text.replace('Speaker 2:', '[è©±è€…2]:')

    # è¤‡æ•°è¡Œã®ã‚»ãƒªãƒ•ã‚’1è¡Œã«ã¾ã¨ã‚ã‚‹
    lines = text.split('\n')
    result = []
    current_speaker = None
    current_text = []

    for line in lines:
        line = line.strip()
        if not line:
            continue

        match = re.match(r'\[(è©±è€…\d+)\]:\s*(.*)', line)
        if match:
            if current_speaker and current_text:
                combined = ' '.join(current_text)
                combined = re.sub(r'\*\*', '', combined)
                combined = re.sub(r'\([^)]*\)', '', combined)
                result.append(f'[{current_speaker}]: {combined}')

            current_speaker = match.group(1)
            current_text = [match.group(2)] if match.group(2) else []
        elif current_speaker:
            if not line.startswith('(') and not line.startswith('â– ') and not line.startswith('ã€'):
                current_text.append(line)

    if current_speaker and current_text:
        combined = ' '.join(current_text)
        combined = re.sub(r'\*\*', '', combined)
        result.append(f'[{current_speaker}]: {combined}')

    return '\n'.join(result)

# WAVãƒ•ã‚¡ã‚¤ãƒ«çµåˆï¼ˆpydubä¸è¦ï¼‰
def combine_wav_files(wav_files, output_path):
    """Combine multiple WAV files into one."""
    if not wav_files:
        return

    # æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
    with wave.open(wav_files[0], 'rb') as first:
        params = first.getparams()

    # ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ï¼ˆ300msï¼‰
    silence_frames = int(params.framerate * 0.3) * params.nchannels * params.sampwidth
    silence = b'\x00' * silence_frames

    # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ
    with wave.open(output_path, 'wb') as output:
        output.setparams(params)
        for wav_file in wav_files:
            with wave.open(wav_file, 'rb') as w:
                output.writeframes(w.readframes(w.getnframes()))
            output.writeframes(silence)

# WAVã‚’MP3ã«å¤‰æ›
def wav_to_mp3(wav_path, mp3_path):
    """Convert WAV to MP3 using ffmpeg."""
    try:
        subprocess.run(
            ['ffmpeg', '-y', '-i', wav_path, '-codec:a', 'libmp3lame', '-q:a', '2', mp3_path],
            capture_output=True,
            check=True
        )
        return True
    except:
        return False

# éŸ³å£°ç”Ÿæˆ
def generate_audio(segments, progress_bar, status_text):
    speakers = list(set(seg["speaker"] for seg in segments))
    female_voices = ["Aoede", "Kore", "Leda", "Zephyr"]
    male_voices = ["Charon", "Puck", "Orus", "Fenrir"]

    speaker_voices = {}
    speaker_styles = {}

    for i, speaker in enumerate(sorted(speakers)):
        if i % 2 == 0:
            speaker_voices[speaker] = female_voices[i // 2 % len(female_voices)]
            speaker_styles[speaker] = "as an expressive young woman speaking Japanese"
        else:
            speaker_voices[speaker] = male_voices[i // 2 % len(male_voices)]
            speaker_styles[speaker] = "as a calm knowledgeable expert speaking Japanese"

    temp_files = []
    temp_dir = tempfile.mkdtemp()

    for i, segment in enumerate(segments):
        speaker = segment["speaker"]
        text = segment["text"]
        voice = speaker_voices.get(speaker, "Kore")
        style = speaker_styles.get(speaker, "")

        prompt = f"Say {style}: {text}" if style else text

        try:
            response = client.models.generate_content(
                model="gemini-2.5-flash-preview-tts",
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_modalities=["AUDIO"],
                    speech_config=types.SpeechConfig(
                        voice_config=types.VoiceConfig(
                            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                voice_name=voice,
                            )
                        )
                    ),
                ),
            )

            audio_data = response.candidates[0].content.parts[0].inline_data.data
            temp_path = os.path.join(temp_dir, f"segment_{i}.wav")

            with wave.open(temp_path, "wb") as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(24000)
                wf.writeframes(audio_data)

            temp_files.append(temp_path)

            progress_bar.progress((i + 1) / len(segments))
            status_text.text(f"ç”Ÿæˆä¸­: {i+1}/{len(segments)} - {speaker}: {text[:30]}...")

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

    # éŸ³å£°ã‚’çµåˆ
    status_text.text("éŸ³å£°ã‚’çµåˆä¸­...")
    combined_wav = os.path.join(temp_dir, "combined.wav")
    combine_wav_files(temp_files, combined_wav)

    # MP3ã«å¤‰æ›
    combined_mp3 = os.path.join(temp_dir, "output.mp3")
    if wav_to_mp3(combined_wav, combined_mp3):
        with open(combined_mp3, 'rb') as f:
            output_buffer = io.BytesIO(f.read())
    else:
        # MP3å¤‰æ›å¤±æ•—æ™‚ã¯WAVã‚’è¿”ã™
        with open(combined_wav, 'rb') as f:
            output_buffer = io.BytesIO(f.read())

    output_buffer.seek(0)

    # é•·ã•ã‚’è¨ˆç®—
    with wave.open(combined_wav, 'rb') as w:
        duration = w.getnframes() / w.getframerate()

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
    for f in temp_files:
        try:
            os.remove(f)
        except:
            pass
    try:
        os.remove(combined_wav)
        os.remove(combined_mp3)
        os.rmdir(temp_dir)
    except:
        pass

    return output_buffer, duration

# å…¥åŠ›æ–¹æ³•é¸æŠ
st.subheader("ğŸ“ ã‚¹ã‚¯ãƒªãƒ—ãƒˆå…¥åŠ›")
input_method = st.radio(
    "å…¥åŠ›æ–¹æ³•ã‚’é¸æŠ",
    ["ãƒ†ã‚­ã‚¹ãƒˆç›´æ¥å…¥åŠ›", "Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"],
    horizontal=True
)

script = ""

if input_method == "Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    uploaded_file = st.file_uploader("Wordãƒ•ã‚¡ã‚¤ãƒ« (.docx)", type=["docx"])
    if uploaded_file:
        script = read_word_file(uploaded_file)
        st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†!")
        with st.expander("èª­ã¿è¾¼ã‚“ã ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"):
            st.text(script[:1000] + "..." if len(script) > 1000 else script)
else:
    script = st.text_area(
        "ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å…¥åŠ›",
        height=200,
        placeholder="""[è©±è€…1]: ã“ã‚“ã«ã¡ã¯
[è©±è€…2]: ãŠå…ƒæ°—ã§ã™ã‹ï¼Ÿ
[è©±è€…1]: ã¯ã„ã€å…ƒæ°—ã§ã™"""
    )

# ç”Ÿæˆãƒœã‚¿ãƒ³
if st.button("ğŸ™ï¸ éŸ³å£°ã‚’ç”Ÿæˆ", type="primary", use_container_width=True):
    if not script:
        st.error("ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        segments = parse_dialogue(script)

        if not segments:
            st.error("å¯¾è©±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.info("å½¢å¼: [è©±è€…1]: ã‚»ãƒªãƒ•")
        else:
            st.info(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(segments)}")

            progress_bar = st.progress(0)
            status_text = st.empty()

            audio_buffer, duration = generate_audio(segments, progress_bar, status_text)

            status_text.text("")
            st.success(f"âœ… å®Œäº†! (é•·ã•: {int(duration // 60)}åˆ†{int(duration % 60)}ç§’)")

            # å†ç”Ÿ
            st.audio(audio_buffer, format="audio/mp3")

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            st.download_button(
                label="ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=audio_buffer,
                file_name="output.mp3",
                mime="audio/mp3",
                use_container_width=True
            )
